{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16c819ed-9bef-4b54-be72-78f493b46c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae980a76-0b94-4642-b681-761b18bebdf6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57d64c4a-db47-47ac-bed6-9070a305cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    dirPath = os.getcwd()\n",
    "    acce_columns = ['time', 'acce_x', 'acce_y', 'acce_z']\n",
    "    linacce_columns = ['time', 'linacce_x', 'linacce_y', 'linacce_z']\n",
    "    gyro_columns = ['time', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    \n",
    "    allData = list()\n",
    "    \n",
    "    for dataDir in os.listdir(dirPath + \"/allData\"):\n",
    "        path = dirPath + \"/allData/\" + dataDir + \"/\"\n",
    "        acce_columns = ['time', 'acce_x', 'acce_y', 'acce_z']\n",
    "        gyro_columns = ['time', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "        if (dataDir.split('_'))[1] == \"walk\":\n",
    "            lable = 1\n",
    "        else:\n",
    "            lable = 0\n",
    "        \n",
    "        df_acce = pd.read_csv(path+\"acce.txt\", skiprows=1, names=acce_columns, delim_whitespace=True)\n",
    "        df_acce = df_acce.drop(\"time\", axis=1)\n",
    "        df_gyro = pd.read_csv(path+\"gyro.txt\", skiprows=1, names=gyro_columns, delim_whitespace=True)\n",
    "        df_gyro = df_gyro.drop(\"time\", axis=1)\n",
    "        df_linacce = pd.read_csv(path+\"linacce.txt\", skiprows=1, names=linacce_columns, delim_whitespace=True)\n",
    "        df_linacce = df_linacce.drop(\"time\", axis=1)\n",
    "\n",
    "        df_new = pd.concat([df_acce, df_gyro, df_linacce], axis=1)\n",
    "        df_new[\"label\"] = lable\n",
    "        allData.append(df_new)\n",
    "    \n",
    "    return pd.concat(allData, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57595a16-4900-415b-b160-24d1c9df41c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6893/2576324855.py:18: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_acce = pd.read_csv(path+\"acce.txt\", skiprows=1, names=acce_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:20: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_gyro = pd.read_csv(path+\"gyro.txt\", skiprows=1, names=gyro_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:22: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_linacce = pd.read_csv(path+\"linacce.txt\", skiprows=1, names=linacce_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:18: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_acce = pd.read_csv(path+\"acce.txt\", skiprows=1, names=acce_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:20: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_gyro = pd.read_csv(path+\"gyro.txt\", skiprows=1, names=gyro_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:22: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_linacce = pd.read_csv(path+\"linacce.txt\", skiprows=1, names=linacce_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:18: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_acce = pd.read_csv(path+\"acce.txt\", skiprows=1, names=acce_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:20: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_gyro = pd.read_csv(path+\"gyro.txt\", skiprows=1, names=gyro_columns, delim_whitespace=True)\n",
      "/tmp/ipykernel_6893/2576324855.py:22: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_linacce = pd.read_csv(path+\"linacce.txt\", skiprows=1, names=linacce_columns, delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "data = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "413d917c-ce7e-4b92-a75d-d6b6f67c9058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.fillna(data.mean(), inplace=True)\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "797fb8ac-cfb8-4381-9622-4e31dc428305",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241de2ba-5636-40fb-8c85-705ce8c7664d",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "234209df-b64e-4fc2-8c2f-a06a7704a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, labels, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = labels[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "794e4260-2aa1-44b6-ad06-9923537226b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "X_sequences, y_sequences = create_sequences(X, y, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ae886db-7d40-422a-b465-9c2eec220ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4bf2ddb-a15c-4b50-8ac5-d406d8094951",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301bb77-2ece-4efc-9889-f508204536c9",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ee03a9a-635a-49e4-ad8e-55a0518c77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalkDetectionRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(WalkDetectionRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b3515-0953-434c-a3da-347c38ace9ca",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb3fb54c-0d19-4952-914b-1dc348c979a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[2]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bd7c3c8-73b6-4c67-92a2-5c8b8c98966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WalkDetectionRNN(input_size, hidden_size, output_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e87d0f7-68ff-4fa3-9425-8c19f7be4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcb25a7b-2e0d-4085-bfa9-eaf9bd6eba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.6251\n",
      "Epoch [20/200], Loss: 0.5417\n",
      "Epoch [30/200], Loss: 0.4888\n",
      "Epoch [40/200], Loss: 0.3730\n",
      "Epoch [50/200], Loss: 0.2352\n",
      "Epoch [60/200], Loss: 0.1702\n",
      "Epoch [70/200], Loss: 0.1370\n",
      "Epoch [80/200], Loss: 0.1007\n",
      "Epoch [90/200], Loss: 0.0625\n",
      "Epoch [100/200], Loss: 0.0378\n",
      "Epoch [110/200], Loss: 0.0266\n",
      "Epoch [120/200], Loss: 0.0206\n",
      "Epoch [130/200], Loss: 0.0163\n",
      "Epoch [140/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0109\n",
      "Epoch [160/200], Loss: 0.0092\n",
      "Epoch [170/200], Loss: 0.0079\n",
      "Epoch [180/200], Loss: 0.0069\n",
      "Epoch [190/200], Loss: 0.0060\n",
      "Epoch [200/200], Loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf010dc0-5dd5-44eb-9fc9-566edc94978a",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1afae82-5c60-4ae2-b964-2c5e3581e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9980\n",
      "Test Loss: 0.0106\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs.squeeze(), y_test_tensor)\n",
    "    predicted = (test_outputs.squeeze() > 0.5).float()\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a103f-3892-4266-90c5-a41392b2a477",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18fd88f1-0230-4d8d-90b2-1737a5998e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(model, X_test_tensor)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"model.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fe055-8dde-480c-9337-48b798548f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
